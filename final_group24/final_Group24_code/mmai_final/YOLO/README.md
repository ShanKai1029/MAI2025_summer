# Multimodal AI Final Project: PPT Image Detection & Manipulation

æœ¬å°ˆæ¡ˆæ˜¯ä¸€å€‹å¤šæ¨¡æ…‹ AI Pipelineï¼Œçµåˆ **YOLOv8**ï¼ˆç‰©ä»¶åµæ¸¬ï¼‰èˆ‡ **SAM (Segment Anything Model)**ï¼ˆå½±åƒåˆ†å‰²ï¼‰ï¼Œç›®æ¨™æ˜¯ **è‡ªå‹•åµæ¸¬ä¸¦åˆ†å‰² PowerPoint æŠ•å½±ç‰‡ä¸­çš„æ’åœ–**ï¼Œä»¥æ”¯æ´å¾ŒçºŒçš„åœ–ç‰‡ç·¨è¼¯ã€å»èƒŒèˆ‡ç§»å‹•æ‡‰ç”¨ã€‚

---

## ğŸ“‹ ç›®éŒ„ (Table of Contents)

1. [å°ˆæ¡ˆæ¦‚è¿° (Overview)](#å°ˆæ¡ˆæ¦‚è¿°-overview)
2. [ç’°å¢ƒå®‰è£ (Installation)](#ç’°å¢ƒå®‰è£-installation)
3. [è³‡æ–™æº–å‚™ (Data Preparation)](#è³‡æ–™æº–å‚™-data-preparation)
4. [æ¨¡å‹è¨“ç·´ (Training)](#æ¨¡å‹è¨“ç·´-training)
5. [è¨“ç·´çµæœåˆ†æ (Evaluation)](#è¨“ç·´çµæœåˆ†æ-evaluation)
6. [Demo èˆ‡è¦–è¦ºåŒ– (Visualization)](#demo-èˆ‡è¦–è¦ºåŒ–-visualization)
7. [æª”æ¡ˆçµæ§‹ (File Structure)](#æª”æ¡ˆçµæ§‹-file-structure)

---

## å°ˆæ¡ˆæ¦‚è¿° (Overview)

æœ¬å°ˆæ¡ˆåœ¨ **RTX 4090 (24GB VRAM)** ç’°å¢ƒä¸‹å®Œæˆè¨“ç·´èˆ‡å¯¦é©—ï¼Œæ•´é«”æµç¨‹å¦‚ä¸‹ï¼š

1. **Detection**
   ä½¿ç”¨ Fine-tuned **YOLOv8l** åµæ¸¬ PowerPoint æŠ•å½±ç‰‡ä¸­çš„æ’åœ–ä½ç½®ï¼ˆBounding Boxï¼‰ã€‚

2. **Segmentation**
   å°‡ YOLO åµæ¸¬åˆ°çš„ Bounding Box ä½œç‚º Promptï¼Œè¼¸å…¥è‡³ **SAM**ï¼Œé€²è¡Œåƒç´ ç´šå½±åƒåˆ†å‰²èˆ‡å»èƒŒã€‚

3. **Application**
   å¯¦ç¾æŠ•å½±ç‰‡æ’åœ–çš„è‡ªå‹•æ“·å–ã€ç§»å‹•èˆ‡å¾ŒçºŒè¦–è¦ºè™•ç†æ‡‰ç”¨ã€‚

---

## ç’°å¢ƒå®‰è£ (Installation)

æœ¬å°ˆæ¡ˆä½¿ç”¨ **uv** é€²è¡Œç¾ä»£åŒ– Python å¥—ä»¶èˆ‡è™›æ“¬ç’°å¢ƒç®¡ç†ã€‚

### 1ï¸âƒ£ åˆå§‹åŒ–ç’°å¢ƒï¼ˆPython 3.10ï¼‰

```bash
uv init
uv python pin 3.10
```

### 2ï¸âƒ£ å®‰è£æ ¸å¿ƒä¾è³´

```bash
# ultralytics: YOLOv8 æ¡†æ¶
# segment-anything: Meta SAM æ¨¡å‹
# opencv-python: å½±åƒè™•ç†
# matplotlib: è¦–è¦ºåŒ–
uv add ultralytics opencv-python matplotlib segment-anything
```

### 3ï¸âƒ£ ï¼ˆOptionalï¼‰ä¸‹è¼‰ SAM æ¬Šé‡

```bash
wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
```

---

## è³‡æ–™æº–å‚™ (Data Preparation)

åŸå§‹è³‡æ–™ç‚º **JSON æ ¼å¼æ¨™è¨»**ï¼Œä»¥ Pixel Coordinates æè¿°ç‰©ä»¶ä½ç½®ï¼Œä¸¦åŒ…å«ä¸‰ç¨®è¦–åœ–ï¼š

* **Source**
* **Target**
* **Mask**

æœ¬å°ˆæ¡ˆä½¿ç”¨è‡ªè£½è…³æœ¬ï¼Œå°‡ JSON æ¨™è¨»è½‰æ›ç‚º **YOLO Detection æ ¼å¼**ï¼Œä¸¦åŒæ™‚é€²è¡Œè³‡æ–™æ“´å¢ï¼Œä½¿è³‡æ–™é‡æå‡ **3 å€**ã€‚

### 3.1 åŸ·è¡Œè³‡æ–™è½‰æ›è…³æœ¬

```bash
uv run convert_json_to_yolo_v3.py
```

æ­¤è…³æœ¬æœƒï¼š

* è®€å– `annotations.json`
* è‡ªå‹•æ‹†è§£ Source / Target / Mask
* é‡æ–°è¨ˆç®— Bounding Box
* è¼¸å‡º YOLO è¨“ç·´æ‰€éœ€çš„ images / labels

---

### 3.2 å»ºç«‹ YOLO Dataset è¨­å®šæª”

è«‹ç¢ºèªè³‡æ–™å·²æˆåŠŸè½‰æ›è‡³ `datasets/ppt_yolo_final/`ï¼Œä¸¦è¨­å®š `ppt_final.yaml`ï¼š

```yaml
# ppt_final.yaml
path: /local/shankai/Multimodal/final/datasets/ppt_yolo_final  # è«‹ç¢ºèªç‚ºçµ•å°è·¯å¾‘
train: train/images
val: val/images

nc: 1
names: ['slide_image']
```

---

## æ¨¡å‹è¨“ç·´ (Training)

æœ¬å°ˆæ¡ˆé‡å° **RTX 4090** é€²è¡Œè¨“ç·´åƒæ•¸å„ªåŒ–ï¼Œä»¥æ¸›å°‘ CPU Data Loading ç“¶é ¸ä¸¦æœ€å¤§åŒ– GPU ä½¿ç”¨ç‡ã€‚

### åŸ·è¡Œè¨“ç·´

```bash
uv run train.py
```

### æ ¸å¿ƒè¨“ç·´åƒæ•¸ï¼ˆ`train.py`ï¼‰

* **Model**: `yolov8l.pt`
  ä½¿ç”¨ Large Model ä»¥æå‡åµæ¸¬æº–ç¢ºç‡

* **Epochs**: `100`

* **Batch Size**: `32`
  é‡å° 24GB VRAM é€²è¡Œæœ€ä½³åŒ–

* **Workers**: `16`
  åŠ é€Ÿ DataLoader

* **Cache**: `True`
  å°‡å½±åƒå¿«å–è‡³ RAMï¼Œå¤§å¹…æå‡è¨“ç·´é€Ÿåº¦

---

## è¨“ç·´çµæœåˆ†æ (Evaluation)

è¨“ç·´å®Œæˆå¾Œï¼Œçµæœæœƒè¼¸å‡ºè‡³ï¼š

```text
runs/detect/ppt_finetune_v1/
```

ï¼ˆå¯¦éš›è³‡æ–™å¤¾åç¨±ä¾ç‰ˆæœ¬è™Ÿè€Œå®šï¼‰

### é—œéµè©•ä¼°æŒ‡æ¨™ï¼ˆ`results.png`ï¼‰

* **Loss Curves**

  * `train/box_loss`
  * `train/cls_loss`
    æ‡‰å‘ˆç¾ç©©å®šä¸”å¹³æ»‘çš„ä¸‹é™è¶¨å‹¢

* **mAP Metrics**

  * **mAP50**ï¼šç‰©ä»¶åµæ¸¬æº–ç¢ºç‡ï¼ˆç†æƒ³å€¼ > 0.95ï¼‰
  * **mAP50-95**ï¼šé«˜ç²¾åº¦é‚Šç•Œæº–ç¢ºç‡

### åˆ†æçµæœ

æœ¬æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šé”åˆ°ï¼š

* **mAP50 = 1.0**

é¡¯ç¤ºæ¨¡å‹å·²èƒ½æ¥µç‚ºç²¾æº–åœ°å­¸ç¿’ PPT æ’åœ–çš„è¦–è¦ºç‰¹å¾µã€‚

---

## Demo èˆ‡è¦–è¦ºåŒ– (Visualization)

ç‚ºæœŸæœ«å ±å‘Šèˆ‡å¯¦é©—å±•ç¤ºï¼Œæœ¬å°ˆæ¡ˆæä¾›å¤šç¨®è¦–è¦ºåŒ–è…³æœ¬ã€‚

### 6.1 Ground Truth vs Prediction å°æ¯”

```bash
uv run visualize_comparison.py
```

è¼¸å‡ºä½ç½®ï¼š

```text
runs/demo/comparison_results/
```

é¡è‰²èªªæ˜ï¼š

* ğŸŸ© **ç¶ è‰²æ¡†**ï¼šGround Truthï¼ˆäººå·¥æ¨™è¨»ï¼‰
* ğŸŸ¥ **ç´…è‰²æ¡†**ï¼šModel Predictionï¼ˆæ¨¡å‹é æ¸¬ï¼‰

åˆ¤è®€æ–¹å¼ï¼š

* ç¶ ç´…æ¡†é‡ç–Šåº¦ï¼ˆIoUï¼‰è¶Šé«˜ï¼Œä»£è¡¨æ¨¡å‹è¶Šæº–ç¢º

---

### 6.2 SAM åˆ†å‰² Pipeline Demo

```bash
uv run run_sam.py
```

æ­¤ Demo å±•ç¤ºå®Œæ•´æµç¨‹ï¼š

1. YOLO åµæ¸¬ Bounding Box
2. SAM ç”Ÿæˆç²¾ç´° Mask
3. å»èƒŒä¸¦è¼¸å‡ºå¯ç¨ç«‹ä½¿ç”¨çš„æ’åœ–ç´ æ

---

## æª”æ¡ˆçµæ§‹ (File Structure)

```text
Multimodal_Final/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ raw_images/             # åŸå§‹åœ–ç‰‡ (Source / Target / Mask)
â”‚   â”œâ”€â”€ annotations.json        # åŸå§‹ JSON æ¨™è¨»
â”‚   â””â”€â”€ ppt_yolo_final/         # [Generated] YOLO æ ¼å¼è¨“ç·´è³‡æ–™
â”œâ”€â”€ runs/
â”‚   â”œâ”€â”€ detect/                 # è¨“ç·´æ¬Šé‡èˆ‡ Logï¼ˆbest.pt åœ¨æ­¤ï¼‰
â”‚   â””â”€â”€ demo/                   # è¦–è¦ºåŒ–è¼¸å‡ºçµæœ
â”œâ”€â”€ convert_json_to_yolo_v3.py  # è³‡æ–™è™•ç†èˆ‡è³‡æ–™æ“´å¢è…³æœ¬
â”œâ”€â”€ train.py                    # YOLO è¨“ç·´è…³æœ¬
â”œâ”€â”€ visualize_comparison.py     # é æ¸¬çµæœå°æ¯”è…³æœ¬
â”œâ”€â”€ run_sam.py                  # SAM åˆ†å‰²èˆ‡å»èƒŒ Pipeline
â”œâ”€â”€ ppt_final.yaml              # YOLO Dataset è¨­å®šæª”
â””â”€â”€ README.md                   # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
```

---

## ğŸ“Œ å‚™è¨» (Notes)

* è«‹ç¢ºèª `.gitignore` å·²æ­£ç¢ºæ’é™¤ï¼š

  * è¨“ç·´è¼¸å‡º (`runs/`)
  * æ¬Šé‡æª” (`*.pt`, `*.pth`)
  * ç§æœ‰è³‡æ–™é›†
* è‹¥ç”¨æ–¼ä½œå“é›†æˆ–å…¬é–‹ Repoï¼Œè«‹é¿å…ä¸Šå‚³åŸå§‹æ¨™è¨»è³‡æ–™èˆ‡æ¨¡å‹æ¬Šé‡
